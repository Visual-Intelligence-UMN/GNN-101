{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12467823,"sourceType":"datasetVersion","datasetId":7865604}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"_uuid":"39a82342-c2ab-4582-bc3d-1ddfbcd122f8","_cell_guid":"d863477d-ed26-4ca1-bccd-90b9902e6cd7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-16T17:08:50.275598Z","iopub.execute_input":"2025-07-16T17:08:50.275834Z","iopub.status.idle":"2025-07-16T17:08:57.977360Z","shell.execute_reply.started":"2025-07-16T17:08:50.275810Z","shell.execute_reply":"2025-07-16T17:08:57.976051Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Simulated GCN Model","metadata":{"_uuid":"9896cc7b-82fd-4ea2-a71b-929b3c424866","_cell_guid":"f506f1d2-2be0-438d-96fb-216bf62ebfd4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Linear\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\nfrom torch_geometric.nn import global_mean_pool\n\nclass gcn_graph_model(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super(gcn_graph_model, self).__init__()\n        torch.manual_seed(12345)\n        self.conv1 = GCNConv(5, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n        self.lin = Linear(hidden_channels, 2)\n\n    def forward(self, x, edge_index, batch):\n        outputs = {}\n        # print(\"Input shapes:\")\n        # print(\"x:\", x.shape)\n        # print(\"edge_index:\", edge_index.shape)\n        # print(\"batch:\", batch.shape)\n        # 1. Obtain node embeddings\n        edge_index = edge_index.to(torch.int64)\n        batch = batch.to(torch.int64)\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        outputs['conv1'] = x\n        x = self.conv2(x, edge_index)\n        x = x.relu()\n        outputs['conv2'] = x\n        x = self.conv3(x, edge_index)\n        outputs['conv3'] = x\n        # 2. Readout layer\n        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n        outputs[\"pooling\"] = x\n        # 3. Apply a final classifier\n        x = F.dropout(x, p=0.5, training=self.training)\n        outputs[\"dropout\"] = x\n        x = self.lin(x)\n        outputs['final'] = x\n        return outputs","metadata":{"_uuid":"a023b5d7-9082-4d26-93b9-59e4fc9547d0","_cell_guid":"fe008df7-841c-4b72-855b-5fa31bbcf16e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-16T17:59:03.263851Z","iopub.execute_input":"2025-07-16T17:59:03.264221Z","iopub.status.idle":"2025-07-16T17:59:03.274821Z","shell.execute_reply.started":"2025-07-16T17:59:03.264197Z","shell.execute_reply":"2025-07-16T17:59:03.273642Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Simulated GCN(node-based) Model","metadata":{"_uuid":"7490c5f8-c62d-4503-a71b-572c9302c55e","_cell_guid":"b5771f5c-8f45-4b99-b2eb-be491598e561","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class gcn_node_model(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super(gcn_node_model, self).__init__()\n        torch.manual_seed(12345)\n        self.conv1 = GCNConv(5, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n        self.lin = Linear(hidden_channels, 2)\n\n    def forward(self, x, edge_index, batch):\n        outputs = {}\n        h = self.conv1(x, edge_index)\n        h = h.tanh()\n        outputs[\"conv1\"] = h\n        h = self.conv2(h, edge_index)\n        h = h.tanh()\n        outputs[\"conv2\"] = h\n        h = self.conv3(h, edge_index)\n        h = h.tanh()  # Final GNN embedding space.\n        outputs[\"conv3\"] = h\n        # Apply a final (linear) classifier.\n        out = self.lin(h)\n        outputs[\"final\"] = out\n        return outputs","metadata":{"_uuid":"2d50c1d2-3220-4208-b067-8bdafee37ffa","_cell_guid":"ffc09866-eaf3-4189-a8c8-6a920b745769","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-16T17:59:07.559007Z","iopub.execute_input":"2025-07-16T17:59:07.559290Z","iopub.status.idle":"2025-07-16T17:59:07.567032Z","shell.execute_reply.started":"2025-07-16T17:59:07.559271Z","shell.execute_reply":"2025-07-16T17:59:07.566002Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# Simulated GCN(edge-based) Model","metadata":{"_uuid":"6e4ef847-7003-4568-8385-ca53a9534cb3","_cell_guid":"717a0866-3d50-403b-b397-d9cd2c781604","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nfrom torch.nn import Linear\nfrom torch_geometric.nn import GCNConv\n\nclass gcn_edge_model(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super(gcn_edge_model, self).__init__()\n        torch.manual_seed(12345)\n        self.conv1 = GCNConv(5, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n        self.lin = Linear(hidden_channels, 2)  # 可选：如果做二分类标签预测\n\n    def encode(self, x, edge_index):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = self.conv3(x, edge_index).tanh()\n        return x\n\n    def decode(self, z, edge_label_index):\n        # Inner product decoder\n        x = (z[edge_label_index[0]] * z[edge_label_index[1]])\n        x = x.sum(dim=-1)  # shape [num_edges]\n        return x\n\n    def decode_all(self, z):\n        prob_adj = z @ z.t()\n        return (prob_adj > 0).nonzero(as_tuple=False).t()\n\n    def forward(self, x, edge_index, edge_label_index, batch):\n        outputs = {}\n        h = self.conv1(x, edge_index).tanh()\n        outputs[\"conv1\"] = h\n        h = self.conv2(h, edge_index).tanh()\n        outputs[\"conv2\"] = h\n        h = self.conv3(h, edge_index).tanh()\n        outputs[\"conv3\"] = h\n\n        # Decode edge probabilities\n        decode_mul = h[edge_label_index[0]] * h[edge_label_index[1]]\n        decode_sum = decode_mul.sum(dim=-1)\n        outputs[\"decode_mul\"] = decode_mul\n        outputs[\"decode_sum\"] = decode_sum\n\n        prob_adj = h @ h.t()\n        outputs[\"prob_adj\"] = prob_adj\n        outputs[\"decode_all_final\"] = (prob_adj > 0).nonzero(as_tuple=False).t()\n        return outputs","metadata":{"_uuid":"e2c4f423-5deb-4766-837a-28932b86a96f","_cell_guid":"8f5df4e8-8e64-4a04-8e3d-ba40ea7d7cb2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-16T17:59:10.513860Z","iopub.execute_input":"2025-07-16T17:59:10.514163Z","iopub.status.idle":"2025-07-16T17:59:10.525618Z","shell.execute_reply.started":"2025-07-16T17:59:10.514142Z","shell.execute_reply":"2025-07-16T17:59:10.524403Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## GAT Simulated Model","metadata":{"_uuid":"42b2455e-e34b-4755-93e0-955dd6abf66c","_cell_guid":"0b00b68d-c824-422a-b2e5-b0a2893aaa3e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from torch_geometric.nn import GATConv\n\nclass gat_edge_model(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super(gat_edge_model, self).__init__()\n        torch.manual_seed(12345)\n        self.conv1 = GATConv(5, hidden_channels, heads=1, concat=False)\n        self.conv2 = GATConv(hidden_channels, hidden_channels, heads=1, concat=False)\n        self.conv3 = GATConv(hidden_channels, hidden_channels, heads=1, concat=False)\n        self.lin = Linear(hidden_channels, 2)\n\n    def encode(self, x, edge_index):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = self.conv3(x, edge_index).tanh()\n        return x\n\n    def decode(self, z, edge_label_index):\n        x = (z[edge_label_index[0]] * z[edge_label_index[1]])\n        x = x.sum(dim=-1)\n        return x\n\n    def decode_all(self, z):\n        prob_adj = z @ z.t()\n        return (prob_adj > 0).nonzero(as_tuple=False).t()\n\n    def forward(self, x, edge_index, edge_label_index, batch):\n        outputs = {}\n        h = self.conv1(x, edge_index).tanh()\n        outputs[\"conv1\"] = h\n        h = self.conv2(h, edge_index).tanh()\n        outputs[\"conv2\"] = h\n        h = self.conv3(h, edge_index).tanh()\n        outputs[\"conv3\"] = h\n\n        decode_mul = h[edge_label_index[0]] * h[edge_label_index[1]]\n        decode_sum = decode_mul.sum(dim=-1)\n        outputs[\"decode_mul\"] = decode_mul\n        outputs[\"decode_sum\"] = decode_sum\n\n        prob_adj = h @ h.t()\n        outputs[\"prob_adj\"] = prob_adj\n        outputs[\"decode_all_final\"] = (prob_adj > 0).nonzero(as_tuple=False).t()\n        return outputs","metadata":{"_uuid":"d2ebaf69-ec65-45a5-be84-0c6f686b5409","_cell_guid":"9b679679-2078-4b2d-884b-cfece2cb9900","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-16T17:59:21.604662Z","iopub.execute_input":"2025-07-16T17:59:21.605110Z","iopub.status.idle":"2025-07-16T17:59:21.615465Z","shell.execute_reply.started":"2025-07-16T17:59:21.605084Z","shell.execute_reply":"2025-07-16T17:59:21.614623Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Customized SAGEConv Layer","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\n# from graphSAGE.CustomizedMessgPassing import CustomizedMessagePassing\nfrom torch_geometric.utils import add_remaining_self_loops\nfrom torch_geometric.nn.conv import MessagePassing\nimport math\n\ndef uniform(size, tensor):\n    bound = 1.0 / math.sqrt(size)\n    if tensor is not None:\n        tensor.data.uniform_(-bound, bound)\n\nclass testClass():\n    def __init__(self):\n        pass\n\n\nclass ConvSAGE(MessagePassing):\n    r\"\"\"The GraphSAGE operator from the `\"Inductive Representation Learning on\n    Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper\n\n    .. math::\n        \\mathbf{\\hat{x}}_i &= \\mathbf{\\Theta} \\cdot\n        \\mathrm{mean}_{j \\in \\mathcal{N(i) \\cup \\{ i \\}}}(\\mathbf{x}_j)\n\n        \\mathbf{x}^{\\prime}_i &= \\frac{\\mathbf{\\hat{x}}_i}\n        {\\| \\mathbf{\\hat{x}}_i \\|_2}.\n\n    Args:\n        in_channels (int): Size of each input sample.\n        out_channels (int): Size of each output sample.\n        normalize (bool, optional): If set to :obj:`True`, output features\n            will be :math:`\\ell_2`-normalized. (default: :obj:`False`)\n        concat (bool, optional): If set to :obj:`True`, will concatenate\n            current node features with aggregated ones. (default: :obj:`False`)\n        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n            an additive bias. (default: :obj:`True`)\n        **kwargs (optional): Additional arguments of\n            :class:`torch_geometric.nn.conv.MessagePassing`.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, normalize=False,\n                 concat=True, bias=True, **kwargs):\n        super(ConvSAGE, self).__init__(aggr='mean', **kwargs)\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.normalize = normalize\n        self.concat = concat\n\n        in_channels = 2 * in_channels if concat else in_channels\n        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n\n        if bias:\n            self.bias = Parameter(torch.Tensor(out_channels))\n        else:\n            self.register_parameter('bias', None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        uniform(self.weight.size(0), self.weight)\n        uniform(self.weight.size(0), self.bias)\n\n    def forward(self, x, edge_index, edge_weight=None, size=None,\n                res_n_id=None):\n        \"\"\"\n        Args:\n            res_n_id (Tensor, optional): Residual node indices coming from\n                :obj:`DataFlow` generated by :obj:`NeighborSampler` are used to\n                select central node features in :obj:`x`.\n                Required if operating in a bipartite graph and :obj:`concat` is\n                :obj:`True`. (default: :obj:`None`)\n        \"\"\"\n        if not self.concat and torch.is_tensor(x):\n            edge_index, edge_weight = add_remaining_self_loops(\n                edge_index, edge_weight, 1, x.size(0))\n\n        return self.propagate(edge_index, size=size, x=x,\n                              edge_weight=edge_weight, res_n_id=res_n_id)\n\n    def message(self, x_j, edge_weight):\n        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n\n    def update(self, aggr_out, x, res_n_id):\n        if self.concat and torch.is_tensor(x):\n            aggr_out = torch.cat([x, aggr_out], dim=-1)\n        elif self.concat and (isinstance(x, tuple) or isinstance(x, list)):\n            assert res_n_id is not None\n            aggr_out = torch.cat([x[0][res_n_id], aggr_out], dim=-1)\n\n        aggr_out = torch.matmul(aggr_out, self.weight)\n\n        if self.bias is not None:\n            aggr_out = aggr_out + self.bias\n\n        if self.normalize:\n            aggr_out = F.normalize(aggr_out, p=2, dim=-1)\n\n        return aggr_out\n\n    def __repr__(self):\n        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n                                   self.out_channels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:20:57.342676Z","iopub.execute_input":"2025-07-16T18:20:57.343061Z","iopub.status.idle":"2025-07-16T18:20:57.358433Z","shell.execute_reply.started":"2025-07-16T18:20:57.343023Z","shell.execute_reply":"2025-07-16T18:20:57.357233Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"## GraphSAGE Simulated Model","metadata":{"_uuid":"4c6ad671-5b46-40ec-ac9a-9d98de8f6ccb","_cell_guid":"1108d396-aeeb-4d0a-97d4-4fb8da7bb2c5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from torch_geometric.nn import SAGEConv\n\nclass sage_edge_model(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super(sage_edge_model, self).__init__()\n        torch.manual_seed(12345)\n        self.conv1 = ConvSAGE(5, hidden_channels)\n        self.conv2 = ConvSAGE(hidden_channels, hidden_channels)\n        self.conv3 = ConvSAGE(hidden_channels, hidden_channels)\n        self.lin = Linear(hidden_channels, 2)\n\n    def encode(self, x, edge_index):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index).relu()\n        x = self.conv3(x, edge_index).tanh()\n        return x\n\n    def decode(self, z, edge_label_index):\n        x = (z[edge_label_index[0]] * z[edge_label_index[1]])\n        x = x.sum(dim=-1)\n        return x\n\n    def decode_all(self, z):\n        prob_adj = z @ z.t()\n        return (prob_adj > 0).nonzero(as_tuple=False).t()\n\n    def forward(self, x, edge_index, edge_label_index, batch):\n        outputs = {}\n        h = self.conv1(x, edge_index).tanh()\n        outputs[\"conv1\"] = h\n        h = self.conv2(h, edge_index).tanh()\n        outputs[\"conv2\"] = h\n        h = self.conv3(h, edge_index).tanh()\n        outputs[\"conv3\"] = h\n\n        decode_mul = h[edge_label_index[0]] * h[edge_label_index[1]]\n        decode_sum = decode_mul.sum(dim=-1)\n        outputs[\"decode_mul\"] = decode_mul\n        outputs[\"decode_sum\"] = decode_sum\n\n        prob_adj = h @ h.t()\n        outputs[\"prob_adj\"] = prob_adj\n        outputs[\"decode_all_final\"] = (prob_adj > 0).nonzero(as_tuple=False).t()\n        return outputs","metadata":{"_uuid":"5942ae59-7b91-4f10-b1ea-6569bcce9f13","_cell_guid":"e7963d63-848c-4e65-94b8-329af9f81eca","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-16T18:20:10.916858Z","iopub.execute_input":"2025-07-16T18:20:10.917529Z","iopub.status.idle":"2025-07-16T18:20:10.927638Z","shell.execute_reply.started":"2025-07-16T18:20:10.917501Z","shell.execute_reply":"2025-07-16T18:20:10.926554Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"# Model Building","metadata":{"_uuid":"f76676f0-e59c-4db3-9885-e2031f0a5289","_cell_guid":"7eb37c05-3090-4a74-8d2d-f04316c7de13","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np\nimport json \n\nwith open(\"/kaggle/input/graphs/testing_graph.json\", \"r\") as f:\n    testing_graph = json.load(f)\n\nx = torch.tensor(testing_graph[\"x\"], dtype=torch.float32)  # shape: [num_nodes, feature_dim]\nedge_index = torch.tensor(testing_graph[\"edge_index\"], dtype=torch.long)","metadata":{"_uuid":"bed7aca4-dcdc-4ca2-bbcd-f746f3abccdf","_cell_guid":"d206e39c-8c17-46a0-8db2-bbd003967302","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-16T17:59:28.382007Z","iopub.execute_input":"2025-07-16T17:59:28.382331Z","iopub.status.idle":"2025-07-16T17:59:28.397947Z","shell.execute_reply.started":"2025-07-16T17:59:28.382308Z","shell.execute_reply":"2025-07-16T17:59:28.396941Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"x = torch.tensor(testing_graph['x'], dtype=torch.float32)\nedge_index = torch.tensor(testing_graph['edge_index'], dtype=torch.int64)\nbatch = torch.tensor(testing_graph['batch'], dtype=torch.int64)\n\ngcn_graph_model_names = ['conv1', 'conv2', 'conv3', 'pooling','dropout','final']\ngcn_node_model_names = ['conv1', 'conv2', 'conv3', 'final']\ngcn_edge_model_names = ['conv1', 'conv2', 'conv3', 'decode_mul', 'decode_sum', 'prob_adj', 'decode_all_final']\n\ngcn_graph_model_var = gcn_graph_model(hidden_channels=16)\ngcn_node_model_var = gcn_node_model(hidden_channels=16)\ngcn_edge_model_var = gcn_edge_model(hidden_channels=16)\n\ngat_edge_model_var = gat_edge_model(hidden_channels=16)\nsage_edge_model_var = sage_edge_model(hidden_channels=16)\n\nmodel_name_arrays = [\n    gcn_graph_model_names,\n    gcn_node_model_names,\n    gcn_edge_model_names,\n    gcn_edge_model_names,\n    gcn_edge_model_names\n]\n\nmodels = [\n    gcn_graph_model_var,\n    gcn_node_model_var,\n    gcn_edge_model_var,\n    gat_edge_model_var,\n    sage_edge_model_var\n]\n\nmodel_names = [\n    'gcn_graph_model',\n    'gcn_node_model',\n    'gcn_edge_model',\n    'gat_edge_model',\n    'sage_edge_model'\n]\n\ndummy_input = (x, edge_index, batch)\n\nedge_label_index = edge_index\ndummy_edge_input = (x, edge_index, edge_label_index, batch)\n\ninput_arrays = [\n    dummy_input,\n    dummy_input,\n    dummy_edge_input,\n    dummy_edge_input,\n    dummy_edge_input\n]\n\ndef model_building(input_template, output_names, model, model_name):\n    state_dict = model.state_dict()\n    # print(state_dict)\n    json_state_dict = {k: v.tolist() for k, v in state_dict.items()}\n\n    print(json_state_dict.keys())\n    \n    with open(f\"/kaggle/working/simulated_{model_name}_weights.json\", \"w\") as f:\n        json.dump(json_state_dict, f, indent=2)\n    torch.onnx.export(model,               # model being run\n                      input_template,         # model input \n                      f\"/kaggle/working/simulated_{model_name}.onnx\",    # where to save the model\n                      export_params=True,  # store the trained parameter weights inside the model file\n                      opset_version=17,    # the ONNX version to export the model to\n                    #   do_constant_folding=True,  # whether to execute constant folding for optimization\n                      input_names = ['x', 'edge_index', 'batch'],   # the model's input names\n                      output_names=output_names,\n                      dynamic_axes={'x': {0: 'num_nodes'},\n                                    'edge_index': {1: 'num_edges'},\n                                    'batch': {0: 'num_nodes'},\n                                    'output': {0: 'batch_size'}})  # which axes should be considered dynamic)","metadata":{"_uuid":"221e847b-0d01-4a46-b77f-74607bfcaf96","_cell_guid":"16ca3d30-2603-4892-a042-49c254672947","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-16T18:21:03.231901Z","iopub.execute_input":"2025-07-16T18:21:03.232214Z","iopub.status.idle":"2025-07-16T18:21:03.274500Z","shell.execute_reply.started":"2025-07-16T18:21:03.232194Z","shell.execute_reply":"2025-07-16T18:21:03.272960Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"for i in range(5):\n    model_building(input_arrays[i], model_name_arrays[i], models[i], model_names[i])","metadata":{"_uuid":"d430a03b-b6b8-4648-8dbc-679ddfc2909b","_cell_guid":"95be3261-7936-4726-8659-f53bfc923126","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-16T18:21:13.622524Z","iopub.execute_input":"2025-07-16T18:21:13.622941Z","iopub.status.idle":"2025-07-16T18:21:14.760947Z","shell.execute_reply.started":"2025-07-16T18:21:13.622914Z","shell.execute_reply":"2025-07-16T18:21:14.759973Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['conv1.bias', 'conv1.lin.weight', 'conv2.bias', 'conv2.lin.weight', 'conv3.bias', 'conv3.lin.weight', 'lin.weight', 'lin.bias'])\ndict_keys(['conv1.bias', 'conv1.lin.weight', 'conv2.bias', 'conv2.lin.weight', 'conv3.bias', 'conv3.lin.weight', 'lin.weight', 'lin.bias'])\ndict_keys(['conv1.bias', 'conv1.lin.weight', 'conv2.bias', 'conv2.lin.weight', 'conv3.bias', 'conv3.lin.weight', 'lin.weight', 'lin.bias'])\ndict_keys(['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight', 'conv3.att_src', 'conv3.att_dst', 'conv3.bias', 'conv3.lin.weight', 'lin.weight', 'lin.bias'])\ndict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'conv3.weight', 'conv3.bias', 'lin.weight', 'lin.bias'])\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# Model Testing","metadata":{}},{"cell_type":"code","source":"!pip install onnxruntime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:24:03.339891Z","iopub.execute_input":"2025-07-16T18:24:03.340276Z","iopub.status.idle":"2025-07-16T18:24:10.222447Z","shell.execute_reply.started":"2025-07-16T18:24:03.340251Z","shell.execute_reply":"2025-07-16T18:24:10.220945Z"}},"outputs":[{"name":"stdout","text":"Collecting onnxruntime\n  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2.4.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->onnxruntime) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m862.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.1\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import onnxruntime\n\ndef test_all_onnx_models(model_names, input_arrays):\n    print(\"Starting ONNX model testing...\\n\")\n    \n    for model_name, input_data in zip(model_names, input_arrays):\n        model_path = f\"/kaggle/working/simulated_{model_name}.onnx\"\n        print(f\"Testing model: {model_name}\")\n        \n        # 加载 ONNX 模型\n        session = onnxruntime.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n        \n        # 提取输入名称（顺序和 onnx 导出时一致）\n        input_names = [inp.name for inp in session.get_inputs()]\n        input_feed = {}\n\n        # 构造输入映射：PyTorch → NumPy\n        for name, tensor in zip(input_names, input_data):\n            input_feed[name] = tensor.detach().cpu().numpy()\n\n        # 提取输出名称\n        output_names = [out.name for out in session.get_outputs()]\n\n        # 执行 ONNX 推理\n        outputs = session.run(output_names, input_feed)\n        \n        for i, output in enumerate(outputs):\n            print(f\"  Output {i} ({output_names[i]}): shape={output.shape}\")\n        \n        print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:24:22.647557Z","iopub.execute_input":"2025-07-16T18:24:22.648089Z","iopub.status.idle":"2025-07-16T18:24:22.700930Z","shell.execute_reply.started":"2025-07-16T18:24:22.648054Z","shell.execute_reply":"2025-07-16T18:24:22.699356Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"test_all_onnx_models(model_names, input_arrays)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T18:24:32.790446Z","iopub.execute_input":"2025-07-16T18:24:32.790804Z","iopub.status.idle":"2025-07-16T18:24:33.068061Z","shell.execute_reply.started":"2025-07-16T18:24:32.790779Z","shell.execute_reply":"2025-07-16T18:24:33.067069Z"}},"outputs":[{"name":"stdout","text":"Starting ONNX model testing...\n\nTesting model: gcn_graph_model\n  Output 0 (conv1): shape=(5, 16)\n  Output 1 (conv2): shape=(5, 16)\n  Output 2 (conv3): shape=(5, 16)\n  Output 3 (pooling): shape=(1, 16)\n  Output 4 (dropout): shape=(1, 16)\n  Output 5 (final): shape=(1, 2)\n--------------------------------------------------\nTesting model: gcn_node_model\n  Output 0 (conv1): shape=(5, 16)\n  Output 1 (conv2): shape=(5, 16)\n  Output 2 (conv3): shape=(5, 16)\n  Output 3 (final): shape=(5, 2)\n--------------------------------------------------\nTesting model: gcn_edge_model\n  Output 0 (conv1): shape=(5, 16)\n  Output 1 (conv2): shape=(5, 16)\n  Output 2 (conv3): shape=(5, 16)\n  Output 3 (decode_mul): shape=(14, 16)\n  Output 4 (decode_sum): shape=(14,)\n  Output 5 (prob_adj): shape=(5, 5)\n  Output 6 (decode_all_final): shape=(2, 25)\n--------------------------------------------------\nTesting model: gat_edge_model\n  Output 0 (conv1): shape=(5, 16)\n  Output 1 (conv2): shape=(5, 16)\n  Output 2 (conv3): shape=(5, 16)\n  Output 3 (decode_mul): shape=(14, 16)\n  Output 4 (decode_sum): shape=(14,)\n  Output 5 (prob_adj): shape=(5, 5)\n  Output 6 (decode_all_final): shape=(2, 25)\n--------------------------------------------------\nTesting model: sage_edge_model\n  Output 0 (conv1): shape=(5, 16)\n  Output 1 (conv2): shape=(5, 16)\n  Output 2 (conv3): shape=(5, 16)\n  Output 3 (decode_mul): shape=(14, 16)\n  Output 4 (decode_sum): shape=(14,)\n  Output 5 (prob_adj): shape=(5, 5)\n  Output 6 (decode_all_final): shape=(2, 25)\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"\u001b[0;93m2025-07-16 18:24:33.043091310 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv1/Identity_3_output_0\u001b[m\n\u001b[0;93m2025-07-16 18:24:33.043182377 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv1/Identity_4_output_0\u001b[m\n\u001b[0;93m2025-07-16 18:24:33.043217389 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv1/Identity_7_output_0\u001b[m\n\u001b[0;93m2025-07-16 18:24:33.043557850 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv2/Identity_3_output_0\u001b[m\n\u001b[0;93m2025-07-16 18:24:33.043648961 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv2/Identity_4_output_0\u001b[m\n\u001b[0;93m2025-07-16 18:24:33.043679505 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv2/Identity_7_output_0\u001b[m\n\u001b[0;93m2025-07-16 18:24:33.044173514 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv3/Identity_3_output_0\u001b[m\n\u001b[0;93m2025-07-16 18:24:33.044311716 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv3/Identity_4_output_0\u001b[m\n\u001b[0;93m2025-07-16 18:24:33.044361322 [W:onnxruntime:, execution_frame.cc:876 VerifyOutputSizes] Expected shape from model of {-1} does not match actual shape of {5,1} for output /conv3/Identity_7_output_0\u001b[m\n","output_type":"stream"}],"execution_count":46}]}